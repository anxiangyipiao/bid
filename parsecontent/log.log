2024-07-25 10:51:29 中国标准时间 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: parsecontent)
2024-07-25 10:51:29 中国标准时间 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.0.0, Twisted 22.10.0, Python 3.8.19 (default, Mar 20 2024, 19:55:45) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 24.1.0 (OpenSSL 3.2.1 30 Jan 2024), cryptography 42.0.6, Platform Windows-10-10.0.19044-SP0
2024-07-25 10:51:29 中国标准时间 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'parsecontent',
 'DOWNLOAD_DELAY': 0.5,
 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_DATEFORMAT': '%Y-%m-%d %H:%M:%S %Z',
 'LOG_FILE': 'log.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'parsecontent.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler',
 'SPIDER_MODULES': ['parsecontent.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-07-25 10:51:29 中国标准时间 [scrapy.extensions.telnet] INFO: Telnet Password: bb339d1cc5ac7a1a
2024-07-25 10:51:29 中国标准时间 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2024-07-25 10:51:29 中国标准时间 [content] INFO: Reading start URLs from redis key 'content_items' (batch size: 8, encoding: utf-8)
2024-07-25 10:51:29 中国标准时间 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-07-25 10:51:29 中国标准时间 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-07-25 10:51:29 中国标准时间 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-07-25 10:51:29 中国标准时间 [scrapy.core.engine] INFO: Spider opened
2024-07-25 10:51:29 中国标准时间 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-07-25 10:51:29 中国标准时间 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-07-25 10:51:29 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 10:52:48 中国标准时间 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2024-07-25 10:52:48 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\spiders.py:197: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.crawl is deprecated
  self.crawler.engine.crawl(req, spider=self)

2024-07-25 10:52:48 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 10:52:50 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\spiders.py:197: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.crawl is deprecated
  self.crawler.engine.crawl(req, spider=self)

2024-07-25 10:52:50 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 10:52:54 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\spiders.py:197: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.crawl is deprecated
  self.crawler.engine.crawl(req, spider=self)

2024-07-25 10:52:54 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 10:52:56 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 10:52:58 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 10:52:59 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\spiders.py:197: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.crawl is deprecated
  self.crawler.engine.crawl(req, spider=self)

2024-07-25 10:52:59 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 10:53:28 中国标准时间 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: parsecontent)
2024-07-25 10:53:28 中国标准时间 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.0.0, Twisted 22.10.0, Python 3.8.19 (default, Mar 20 2024, 19:55:45) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 24.1.0 (OpenSSL 3.2.1 30 Jan 2024), cryptography 42.0.6, Platform Windows-10-10.0.19044-SP0
2024-07-25 10:53:28 中国标准时间 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'parsecontent',
 'DOWNLOAD_DELAY': 0.5,
 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_DATEFORMAT': '%Y-%m-%d %H:%M:%S %Z',
 'LOG_FILE': 'log.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'parsecontent.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler',
 'SPIDER_MODULES': ['parsecontent.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-07-25 10:53:28 中国标准时间 [scrapy.extensions.telnet] INFO: Telnet Password: 284766029848bbc6
2024-07-25 10:53:28 中国标准时间 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2024-07-25 10:53:28 中国标准时间 [content] INFO: Reading start URLs from redis key 'content_items' (batch size: 8, encoding: utf-8)
2024-07-25 10:53:28 中国标准时间 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-07-25 10:53:28 中国标准时间 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-07-25 10:53:28 中国标准时间 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-07-25 10:53:28 中国标准时间 [scrapy.core.engine] INFO: Spider opened
2024-07-25 10:53:28 中国标准时间 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-07-25 10:53:28 中国标准时间 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-07-25 10:55:03 中国标准时间 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: parsecontent)
2024-07-25 10:55:03 中国标准时间 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.0.0, Twisted 22.10.0, Python 3.8.19 (default, Mar 20 2024, 19:55:45) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 24.1.0 (OpenSSL 3.2.1 30 Jan 2024), cryptography 42.0.6, Platform Windows-10-10.0.19044-SP0
2024-07-25 10:55:03 中国标准时间 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'parsecontent',
 'DOWNLOAD_DELAY': 0.5,
 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_DATEFORMAT': '%Y-%m-%d %H:%M:%S %Z',
 'LOG_FILE': 'log.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'parsecontent.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler',
 'SPIDER_MODULES': ['parsecontent.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-07-25 10:55:03 中国标准时间 [scrapy.extensions.telnet] INFO: Telnet Password: a6f39d8de0377fa2
2024-07-25 10:55:04 中国标准时间 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2024-07-25 10:55:04 中国标准时间 [content] INFO: Reading start URLs from redis key 'content_items' (batch size: 8, encoding: utf-8)
2024-07-25 10:55:04 中国标准时间 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-07-25 10:55:04 中国标准时间 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-07-25 10:55:04 中国标准时间 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-07-25 10:55:04 中国标准时间 [scrapy.core.engine] INFO: Spider opened
2024-07-25 10:55:04 中国标准时间 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-07-25 10:55:04 中国标准时间 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-07-25 10:55:04 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 10:56:28 中国标准时间 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2024-07-25 10:57:10 中国标准时间 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2024-07-25 10:57:14 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\spiders.py:197: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.crawl is deprecated
  self.crawler.engine.crawl(req, spider=self)

2024-07-25 10:57:14 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 10:57:46 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\spiders.py:197: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.crawl is deprecated
  self.crawler.engine.crawl(req, spider=self)

2024-07-25 10:57:46 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 11:49:42 中国标准时间 [scrapy.utils.log] INFO: Scrapy 2.9.0 started (bot: parsecontent)
2024-07-25 11:49:42 中国标准时间 [scrapy.utils.log] INFO: Versions: lxml 5.2.1.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.0.0, Twisted 22.10.0, Python 3.8.19 (default, Mar 20 2024, 19:55:45) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 24.1.0 (OpenSSL 3.2.1 30 Jan 2024), cryptography 42.0.6, Platform Windows-10-10.0.19044-SP0
2024-07-25 11:49:43 中国标准时间 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'parsecontent',
 'DOWNLOAD_DELAY': 0.5,
 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_DATEFORMAT': '%Y-%m-%d %H:%M:%S %Z',
 'LOG_FILE': 'log.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'parsecontent.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler',
 'SPIDER_MODULES': ['parsecontent.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-07-25 11:49:43 中国标准时间 [scrapy.extensions.telnet] INFO: Telnet Password: 033015b26dc6e189
2024-07-25 11:49:43 中国标准时间 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2024-07-25 11:49:43 中国标准时间 [content] INFO: Reading start URLs from redis key 'content_items' (batch size: 8, encoding: utf-8)
2024-07-25 11:49:43 中国标准时间 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-07-25 11:49:43 中国标准时间 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-07-25 11:49:43 中国标准时间 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-07-25 11:49:43 中国标准时间 [scrapy.core.engine] INFO: Spider opened
2024-07-25 11:49:43 中国标准时间 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-07-25 11:49:43 中国标准时间 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-07-25 11:49:43 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

2024-07-25 11:55:37 中国标准时间 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2024-07-25 11:55:52 中国标准时间 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2024-07-25 11:56:29 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\spiders.py:197: ScrapyDeprecationWarning: Passing a 'spider' argument to ExecutionEngine.crawl is deprecated
  self.crawler.engine.crawl(req, spider=self)

2024-07-25 11:56:29 中国标准时间 [py.warnings] WARNING: d:\anaconda3\envs\crawl\lib\site-packages\scrapy_redis\dupefilter.py:115: ScrapyDeprecationWarning: Call to deprecated function scrapy.utils.request.request_fingerprint().

If you are using this function in a Scrapy component, and you are OK with users of your component changing the fingerprinting algorithm through settings, use crawler.request_fingerprinter.fingerprint() instead in your Scrapy component (you can get the crawler object from the 'from_crawler' class method).

Otherwise, consider using the scrapy.utils.request.fingerprint() function instead.

Either way, the resulting fingerprints will be returned as bytes, not as a string, and they will also be different from those generated by 'request_fingerprint()'. Before you switch, make sure that you understand the consequences of this (e.g. cache invalidation) and are OK with them; otherwise, consider implementing your own function which returns the same fingerprints as the deprecated 'request_fingerprint()' function.
  return request_fingerprint(request)

